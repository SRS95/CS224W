{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/python2/lib/python2.7/site-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "import snap\n",
    "import operator\n",
    "import snap\n",
    "from scipy.stats import binom\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "\n",
    "# Machine learning packages\n",
    "\n",
    "# Supervised learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Unsupervised learning (i.e. clustering)\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# Clustering assessment metrics(for unknown ground truth)\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import calinski_harabaz_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10298\n"
     ]
    }
   ],
   "source": [
    "# Load the embeddings from memory\n",
    "neutral_model = Word2Vec.load_word2vec_format(\"../node2vec_embeddings/companies_final_p1_q1.emd\")\n",
    "print len(neutral_model.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are all of the acquired companies we know about\n",
    "acquired_companies = set(np.load(\"../acquired_companies.npy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21945\n"
     ]
    }
   ],
   "source": [
    "node_id_to_value = np.load(\"../../graphs/investors_to_companies_directed/node_id_to_value.npy\").item()\n",
    "print len(node_id_to_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we find the overlap between companies in our graph and the set of acquired companies\n",
    "FIn = snap.TFIn(\"../../graphs/investors_to_companies_directed/investors_to_companies_directed_folded.graph\")\n",
    "G = snap.TUNGraph.Load(FIn)\n",
    "\n",
    "companies_in_graph = set()\n",
    "for EI in G.Edges(): \n",
    "    curr_src_id = EI.GetSrcNId()\n",
    "    curr_dst_id = EI.GetDstNId()\n",
    "    companies_in_graph.add(node_id_to_value[curr_src_id])\n",
    "    companies_in_graph.add(node_id_to_value[curr_dst_id])\n",
    "    \n",
    "# These are the acquired companies in our folded graph\n",
    "acquired_companies_in_graph = companies_in_graph.intersection(acquired_companies)\n",
    "\n",
    "acquired_companies_in_graph_by_id = []\n",
    "value_to_node_id = {v: k for k, v in node_id_to_value.iteritems()}\n",
    "for company in acquired_companies_in_graph:\n",
    "    acquired_companies_in_graph_by_id.append(value_to_node_id[company])\n",
    "    \n",
    "not_acquired_companies_in_graph = companies_in_graph.difference(acquired_companies)\n",
    "not_acquired_companies_in_graph_by_id = []\n",
    "for company in not_acquired_companies_in_graph:\n",
    "    not_acquired_companies_in_graph_by_id.append(value_to_node_id[company])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns train and test sets with fraction train_frac \n",
    "# of the total number of datapoints in the train set\n",
    "def getData(model, train_frac):\n",
    "    # Use node2vec and logistic regression to make predictions\n",
    "    node_2_vec_embedding_dimension = 128\n",
    "\n",
    "    train_companies = set([])\n",
    "    # Randomly assign train test\n",
    "    for company in companies_in_graph: \n",
    "        if np.random.rand() < train_frac: train_companies.add(company)\n",
    "              \n",
    "    test_companies = companies_in_graph.difference(train_companies)\n",
    "\n",
    "    train_X = np.zeros((len(train_companies), node_2_vec_embedding_dimension))\n",
    "    train_Y = np.zeros((len(train_companies),))\n",
    "\n",
    "    train_companies = list(train_companies)\n",
    "    for i in range(len(train_companies)):\n",
    "        company_id = value_to_node_id[train_companies[i]]\n",
    "        company_embedding = model[str(company_id)]\n",
    "        train_X[i] = company_embedding\n",
    "        if company_id in acquired_companies_in_graph_by_id:\n",
    "            train_Y[i] = 1\n",
    "        else:\n",
    "            train_Y[i] = 0\n",
    "\n",
    "    test_X = np.zeros((len(test_companies), node_2_vec_embedding_dimension))\n",
    "    test_Y = np.zeros((len(test_companies),))\n",
    "\n",
    "    test_companies = list(test_companies)\n",
    "    for i in range(len(test_companies)):\n",
    "        company_id = value_to_node_id[test_companies[i]]\n",
    "        company_embedding = model[str(company_id)]\n",
    "        test_X[i] = company_embedding\n",
    "        if company_id in acquired_companies_in_graph_by_id:\n",
    "            test_Y[i] = 1\n",
    "        else:\n",
    "            test_Y[i] = 0 \n",
    "            \n",
    "    return train_X, train_Y, test_X, test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_supervised_classifier(train_X, train_Y, test_X, test_Y, fitted_model):\n",
    "    train_predictions = fitted_model.predict(train_X)\n",
    "    test_predictions = fitted_model.predict(test_X)\n",
    "    print \"Train confusion matrix (rows correspond to true labels)\"\n",
    "    print confusion_matrix(train_Y, train_predictions, labels=[0, 1])\n",
    "    print \"Test confusion matrix (rows correspond to true labels)\"\n",
    "    print confusion_matrix(test_Y, test_predictions, labels=[0, 1])\n",
    "\n",
    "    print \"Train score\"\n",
    "    print fitted_model.score(train_X, train_Y)\n",
    "    print \"Test score\"\n",
    "    print fitted_model.score(test_X, test_Y)\n",
    "    print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(train_X, train_Y, test_X, test_Y, class_weight):\n",
    "    # Weight the less common class more heavily\n",
    "    # For the confustion matrix, rows correspond to true labels and columns to predicted labels\n",
    "    fitted_model = LogisticRegression(class_weight={0:1, 1:2}).fit(train_X, train_Y)\n",
    "    print \"Successfully fitted logistic regression classifier\"\n",
    "    assess_supervised_classifier(train_X, train_Y, test_X, test_Y, fitted_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we'll try using a decision tree\n",
    "def decision_tree_classifier(train_X, train_Y, test_X, test_Y):\n",
    "    fitted_model = DecisionTreeClassifier().fit(train_X, train_Y)\n",
    "    print \"Successfully fitted decision tree classifier\"\n",
    "    assess_supervised_classifier(train_X, train_Y, test_X, test_Y, fitted_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No surprise that the neural net overfit\n",
    "# Let's now try using KNN\n",
    "def knn_classifier(train_X, train_Y, test_X, test_Y, k):\n",
    "    fitted_model = KNeighborsClassifier(n_neighbors=10).fit(train_X, train_Y)\n",
    "    print \"Successfully fitted KNN classifier\"\n",
    "    assess_supervised_classifier(train_X, train_Y, test_X, test_Y, fitted_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we'll give the random forest a go\n",
    "# This model turns a bunch of weaker decision\n",
    "# models into a more powerful ensemble model\n",
    "def random_forest_classifier(train_X, train_Y, test_X, test_Y):\n",
    "    fitted_model = RandomForestClassifier().fit(train_X, train_Y)\n",
    "    print \"Successfully fitted random forest classifier\"\n",
    "    assess_supervised_classifier(train_X, train_Y, test_X, test_Y, fitted_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks like logistic regression mostly predicts not acquired the vast majority of the time as expected\n",
    "# Let's see if a simple neural net can do any better\n",
    "def mlp_classifier(train_X, train_Y, test_X, test_Y):\n",
    "    fitted_model = MLPClassifier().fit(train_X, train_Y)\n",
    "    print \"Successfully fitted MLP classifier\"\n",
    "    assess_supervised_classifier(train_X, train_Y, test_X, test_Y, fitted_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully fitted logistic regression classifier\n",
      "Train confusion matrix (rows correspond to true labels)\n",
      "[[6930  122]\n",
      " [1070   85]]\n",
      "Test confusion matrix (rows correspond to true labels)\n",
      "[[1757   41]\n",
      " [ 276   17]]\n",
      "Train score\n",
      "0.854758133301\n",
      "Test score\n",
      "0.848397895744\n",
      "\n",
      "Successfully fitted MLP classifier\n",
      "Train confusion matrix (rows correspond to true labels)\n",
      "[[7039   13]\n",
      " [ 637  518]]\n",
      "Test confusion matrix (rows correspond to true labels)\n",
      "[[1725   73]\n",
      " [ 268   25]]\n",
      "Train score\n",
      "0.920799317656\n",
      "Test score\n",
      "0.836920133907\n",
      "\n",
      "Successfully fitted KNN classifier\n",
      "Train confusion matrix (rows correspond to true labels)\n",
      "[[7044    8]\n",
      " [1139   16]]\n",
      "Test confusion matrix (rows correspond to true labels)\n",
      "[[1792    6]\n",
      " [ 293    0]]\n",
      "Train score\n",
      "0.860241257463\n",
      "Test score\n",
      "0.857006217121\n",
      "\n",
      "Successfully fitted decision tree classifier\n",
      "Train confusion matrix (rows correspond to true labels)\n",
      "[[7052    0]\n",
      " [   0 1155]]\n",
      "Test confusion matrix (rows correspond to true labels)\n",
      "[[1504  294]\n",
      " [ 225   68]]\n",
      "Train score\n",
      "1.0\n",
      "Test score\n",
      "0.751793400287\n",
      "\n",
      "Successfully fitted random forest classifier\n",
      "Train confusion matrix (rows correspond to true labels)\n",
      "[[7052    0]\n",
      " [ 175  980]]\n",
      "Test confusion matrix (rows correspond to true labels)\n",
      "[[1782   16]\n",
      " [ 287    6]]\n",
      "Train score\n",
      "0.978676739369\n",
      "Test score\n",
      "0.855093256815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_X, train_Y, test_X, test_Y = getData(neutral_model, 0.8)\n",
    "\n",
    "logistic_regression(train_X, train_Y, test_X, test_Y, {0:1, 1:2})\n",
    "mlp_classifier(train_X, train_Y, test_X, test_Y)\n",
    "knn_classifier(train_X, train_Y, test_X, test_Y, 10)\n",
    "decision_tree_classifier(train_X, train_Y, test_X, test_Y)\n",
    "random_forest_classifier(train_X, train_Y, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also use k means to see how an unsupervised model performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_clustering_model(fitted_model, train_X, test_X=None):\n",
    "    train_is_whole_dataset = True if test_X == None else False\n",
    "    \n",
    "    train_cluster_assignments = fitted_model.predict(train_X)\n",
    "    test_cluster_assignments = None if train_is_whole_dataset else fitted_model.predict(test_X)\n",
    "    \n",
    "    # Compute the mean silhoutte score across all samples\n",
    "    # For silhouette scores, the best value is 1 and the worst value is -1\n",
    "    # Values near 0 indicate overlapping clusters\n",
    "    train_silhouette_score = silhouette_score(train_X, train_cluster_assignments)\n",
    "    test_silhouette_score = None if train_is_whole_dataset else silhouette_score(test_X, test_cluster_assignments)\n",
    "    print \"Train silhouette score:\" \n",
    "    print train_silhouette_score\n",
    "    print \"Test silhouette score:\"\n",
    "    print test_silhouette_score\n",
    "\n",
    "    # Compute the mean Calinski-Harabasz index for all samples\n",
    "    # For Calinski-Harabasz, the higher the better\n",
    "    train_ch_score = calinski_harabaz_score(train_X, train_cluster_assignments)\n",
    "    test_ch_score = None if train_is_whole_dataset else calinski_harabaz_score(test_X, test_cluster_assignments)\n",
    "    print \"Train Calinski-Harabasz score:\"\n",
    "    print train_ch_score\n",
    "    print \"Test Calinski-Harabasz score:\"\n",
    "    print test_ch_score\n",
    "    print \"\"\n",
    "    return test_silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's assume we don't know anything about the companies\n",
    "# We'll use k-means to cluster their node2vec embeddings\n",
    "def k_means(train_X, test_X, k):\n",
    "    fitted_model = KMeans(n_clusters=k).fit(train_X)\n",
    "    print \"Successfully fitted K Means\"\n",
    "    return assess_clustering_model(fitted_model, train_X, test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully fitted K Means\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/python2/lib/python2.7/site-packages/ipykernel_launcher.py:2: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train silhouette score:\n",
      "0.221353668244\n",
      "Test silhouette score:\n",
      "0.212366421773\n",
      "Train Calinski-Harabasz score:\n",
      "792.521008451\n",
      "Test Calinski-Harabasz score:\n",
      "192.471699598\n",
      "\n",
      "Successfully fitted K Means\n",
      "Train silhouette score:\n",
      "0.221353668244\n",
      "Test silhouette score:\n",
      "0.212366421773\n",
      "Train Calinski-Harabasz score:\n",
      "792.521008451\n",
      "Test Calinski-Harabasz score:\n",
      "192.471699598\n",
      "\n",
      "Successfully fitted K Means\n",
      "Train silhouette score:\n",
      "0.221353668244\n",
      "Test silhouette score:\n",
      "0.212366421773\n",
      "Train Calinski-Harabasz score:\n",
      "792.521008451\n",
      "Test Calinski-Harabasz score:\n",
      "192.471699598\n",
      "\n",
      "Successfully fitted K Means\n",
      "Train silhouette score:\n",
      "0.230811490992\n",
      "Test silhouette score:\n",
      "0.217028693192\n",
      "Train Calinski-Harabasz score:\n",
      "792.574030298\n",
      "Test Calinski-Harabasz score:\n",
      "192.250481626\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a18114f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_X, train_Y, test_X, test_Y = getData(neutral_model, 0.8)\n",
    "\n",
    "sil_scores = []\n",
    "x_vals = []\n",
    "for k in range(2, 10, 2):\n",
    "    sil_scores.append(k_means(train_X, k))\n",
    "    x_vals.append(k)\n",
    "    \n",
    "plt.plot(x_vals, ch_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
